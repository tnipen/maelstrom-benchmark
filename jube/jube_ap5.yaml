name:    benchmark
outpath: results
comment: MAELSTROM GPU/CPU benchmark jube script. Currently, WGAN is not supported on IPUs.
# Tags:
# - ipu (IPUS on dc-ipu). Throws an error as it is not supported yet.
# - jwb (GPUs on JUWELS booster)
# - jwc (GPUs on JUWELS cluster)
# - jwr (A100 GPUs on JURECA cluster)
# - amd (CPUs on JUWELS booster)
# - intel (CPUs on JUWELS cluster)
# - h100 (GPUs on JURECA)
# - mi250x (GPUs on JURECA)
# - e4a2 (NVIDIA A2 GPUs on E4)
# - e4gh200 (NVIDIA GraceHopper 200 on E4)

parameterset:
  - name: appParameters
    parameter:
      - name: program
        tag: jwb|jwc|jrc|amd|intel|e4gh200|e4a2
        type: string
        _: python -u $jube_benchmark_home/../benchmark.py
      - name: program
        tag: "ipu"
        type: string
        _: apptainer run $jube_benchmark_home/../ap3.sif -- python -u $jube_benchmark_home/../benchmark.py
      - name: program
        tag: "h100"
        type: string
        _: --mpi=pspmix env PMIX_SECURITY_MODE=native apptainer run --nv $jube_benchmark_home/../h100.sif -- python -u $jube_benchmark_home/../benchmark.py
      - name: program
        tag: "mi250x"
        type: string
        _: --mpi=pmi2 apptainer run $jube_benchmark_home/../mi250x.sif -- python -u $jube_benchmark_home/../benchmark.py
      - name: program
        tag: "e4gh200"
        type: string
        # Use -v, not --mount, since the latter requires commas, which I can't seem to be able to escape in JUBE
        _: "docker run -v $jube_benchmark_home/../:/code --gpus all --shm-size=1g --ulimit memlock=-1 --rm  ap1_maelstrom python -u /code/benchmark.py"
      - name: hardware_name
        type: string
        tag: jwb|jrc
        _: A100_GPU
      - name: hardware_name
        type: string
        tag: jwc
        _: V100_GPU
      - name: hardware_name
        type: string
        tag: ipu
        _: GC200_IPU
      - name: hardware_name
        type: string
        tag: intel
        _: Intel_Xeon_2.7GHz
      - name: hardware_name
        type: string
        tag: amd
        _: AMD_EPYC_2.8GHz
      - name: hardware_name
        type: string
        tag: h100
        _: H100_GPU
      - name: hardware_name
        type: string
        tag: mi250x
        _: MI250_GPU
      - name: hardware
        type: string
        tag: jwb|jwc|jrc|h100|mi250x|e4gh200
        _: gpu
      - name: hardware_name
        type: string
        tag: e4gh200
        _: E4-GH200
      - name: hardware_name
        type: string
        tag: e4a2
        _: E4-A2
      - name: hardware
        type: string
        tag: ipu
        _: ipu
      - name: hardware
        type: string
        tag: amd
        _: cpu
      - name: hardware
        type: string
        tag: intel
        _: cpu
      - name: experiment
        type: int
        _: 0 # ,1,2
      - name: nepochs
        type: int
        _: 4
        # - name: batches_per_epoch
        # type: int
        # _: 80, 160, 320, 640
      - name: batch_size
        tag: ipu
        type: int
        _: 2
      - name: batch_size
        tag: "!ipu"
        type: int
        _: 8,16,32,64,128,256 
      - name: replica
        tag: ipu
        type: int
        _: 16
      - name: replica
        tag: "!ipu"
        type: int
        _: 1
      - name: steps_per_execution
        tag: ipu
        type: int
        _: 3020
      - name: steps_per_execution
        # epoch is defined as number of batches for the WGAN's generator to see the whole dataset once
        # corresponds to number of batches with a batch size of 32 given the dataset size
        tag: "!ipu"
        type: int
        _: 3020
      - name: dataset_size
        # corresponds to 24171*4 samples
        tag: "!intel+!amd"
        type: int
        _:  66827980800 
      - name: dataset_size
        # Use a smaller dataset for CPU benchmarks, otherwise it takes forever (corresponds to 2000 samples)
        tag: intel|amd
        type: int
        _: 1382400000
      - name: patch_size
        type: string
        _: "96 120"
      - name: app
        type: string
        _: ap5
      - name: program_args
        type: string
        _: "-a ${app} -b ${batch_size} -e ${nepochs} -d ${dataset_size} -ps ${patch_size} -w ${hardware} -wn ${hardware_name} -s ${steps_per_execution} -r ${replica}"
  - name: globalParameter
    parameter:
      - name: create_env
        # ipu, h100 and e4a2 don't need any env activated, because they run in a container
        tag: "jwb|jwc|amd|intel|jrc"
        separator: |
        _: 
          cd $jube_benchmark_home/../env_setup/;
          source ./create_env.sh venv_$systemname;
      - name: activate_env
        # ipu, h100 and e4a2 don't need any env activated, because they run in a container
        tag: "jwb|jwc|amd|intel|jrc|e4a2"
        separator: |
        _: 
          source $jube_benchmark_home/../virtual_envs/venv_$systemname/bin/activate;
      - name: modules
        # ipu doesn't need any modules loaded, because it runs in the container
        tag: "jwb|jwc|amd|intel|jrc"
        separator: |
        _: 
          module load Stages/2022 &&
          module load GCCcore/.11.2.0 &&
          module load TensorFlow/2.6.0-CUDA-11.5 &&
          module load GCC/11.2.0 &&
          module load OpenMPI/4.1.2 &&
          module load mpi4py/3.1.3 &&
          module load Horovod/0.24.3  
      - name: modules
        tag: e4a2
        separator: |
        _:
          module load slurm &&
          module load nvidia/cuda-11.7 &&
          module load python/python-3.9.16
      - name: modules
        tag: e4gh200
        separator: |
        _:
          module load slurm &&
          module load nvidia/cuda-12.3 &&
          module load gcc-8.5.0/miniconda-23.10.0-1_aarch64 &&
          eval "$(conda shell.bash hook)"
      - name: systemname
        tag: jwc
        _: jwc
      - name: systemname
        tag: jrc
        _: jrc
      - name: systemname
        tag: jwb
        _: jwb
      - name: systemname
        tag: amd
        _: jwb
      - name: systemname
        tag: intel
        _: jwb
      - name: systemname
        tag: ipu|h100|mi250x
        _: jrc
      - name: systemname
        tag: e4gh200
        _: e4arm
      - name: systemname
        tag: e4a2
        _: e4intel      
  - name: executeset
    init_with: platform.xml
  - name: systemParameter
    init_with: platform.xml
    parameter:
      - name: preprocess
        mode: text
        tag: "jwb|jwc|amd|intel|jrc"
        _:
          $modules;

      - {name: n_cpu, _: 48, tag: jwb}
      - {name: n_cpu, _: 48, tag: jrc}
      - {name: n_cpu, _: 48, tag: amd}
      - {name: n_cpu, _: 48, tag: intel}
      - {name: n_cpu, _: 40, tag: jwc}
      - {name: n_cpu, _: 48, tag: ipu}
      - {name: n_cpu, _: 72, tag: h100}
      - {name: n_cpu, _: 48, tag: mi250x}
      - {name: n_cpu, _: 32, tag: e4gh200}
      - {name: n_cpu, _: 32, tag: e4a2}
      - name: SRUN_CPUS_PER_TASK
        export: true
        _: ${SLURM_CPUS_PER_TASK}
      - name: nodes
        _: 1
      - name: n_procs
        tag: "!ipu|!mi250x!e4a2"
        _: 1,2,4
      - name: n_procs
        tag: e4a2
        _: 1,2 
      - name: n_procs
        tag: "ipu|e4gh200"
        _: 1
      - name: n_procs
        tag: mi250x
        _: 1,2,4,8
      - name: n_gpu
        _: $n_procs
      - name: taskspernode
        _: $n_procs
      - name: threadspertask
        mode: python
        type: int
        _:  ${n_cpu} // ${n_procs}
      - name: extra-node-info
        tag: e4a2
        _: "2:1"
      - name: timelimit
        _: "00:60:00"
      - name: account
        tag: jwb|jwc|amd|intel
        _: deepacf
      - name: account
        tag: jrc
        _: zam
      - name: account
        tag: ipu|h100|mi250x
        _: exalab
      - name: account
        tag: e4gh200|e4a2
      - name: queue
        tag: jwb|amd
        _: booster
      - name: queue
        tag: jwc
        _: develgpus
      - name: queue
        tag: intel
        _: batch
      - name: queue
        tag: ipu
        _: dc-ipu
      - name: queue
        tag: h100
        _: dc-h100
      - name: queue
        tag: mi250x
        _: dc-mi200
      - name: queue
        tag: jrc
        _: dc-gpu-devel
      - name: queue
        tag: e4gh200
        _: t-gpu-gh200
      - name: queue
        tag: e4a2
        _: i-gpu-a2
      - name: gres
        tag: jwb|jwc|jrc|h100|e4gh200|e4a2
        _: gpu:$n_gpu
      - name: additional_job_config
        tag: e4gh200|e4a2
        _: "#SBATCH --mem=256Gb"
      - name: executable
        _: ${program}
      - name: args_exec
        mode: text
        _: > 
          ${program_args}

patternset:
   - name: perf_patterns
     pattern:
      - {name: jobid, type: int, _: "Submitted batch job $jube_pat_int" }
      - {name: hostname, type: string, _: "Hostname: $jube_pat_wrd" }
      - {name: training_time, type: float, _: "Total training time: ${jube_pat_fp} s"}
      - {name: num_weights, type: int, _: "Num trainable weights: ${jube_pat_int}"}
      - {name: dataset_size_mb, type: float, _: "Dataset size: ${jube_pat_fp} MB"}
      - {name: batch_size_mb, type: float, _: "Batch size: ${jube_pat_fp} MB"}
      - {name: batches_per_epoch, type: float, _: "Batches per epoch: ${jube_pat_int}"}
      - {name: actual_steps_per_execution, type: int, _: "Steps per execution: ${jube_pat_int}"}
      - {name: actual_replicas, type: int, _: "Num replicas: ${jube_pat_int}"}
      - {name: epoch_time_first, type: float, _: "First epoch time: $jube_pat_fp s"}
      - {name: epoch_time_nonfirst, type: float, _: "Non-first epoch time: $jube_pat_fp s"}
      - {name: epoch_time_min, type: float, _: "Min epoch time: $jube_pat_fp s"}
      - {name: epoch_time_avg, type: float, _: "Mean epoch time: $jube_pat_fp s"}
      - {name: epoch_time_max, type: float, _: "Max epoch time: $jube_pat_fp s"}
      - {name: cpu_mem, type: float, _: "CPU memory:.*peak: $jube_pat_fp GB"}
      - {name: gpu_mem, type: float, _: "GPU memory:.*peak: $jube_pat_fp GB"}
      - {name: gpu_mem, type: float, _: "GPU memory:.*peak: $jube_pat_fp GB"}
      - {name: total_integrated_energy, type: float, _: "Integrated Total Energy: ${jube_pat_fp} J"}
      - {name: total_counter_energy, type: float, _: "Counter Total Energy: ${jube_pat_fp} J"}
      - {name: max_power, type: float, _: "Max Power: ${jube_pat_fp} W"}
      - {name: performance, type: float, _: "Average performance:\\s+$jube_pat_fp MB/s"}
      - {name: performance_nonfirst_epoch, type: float, _: "Performance non-first epoch:\\s+$jube_pat_fp MB/s"}
      - {name: performance_min_epoch, type: float, _: "Performance min epoch:\\s+$jube_pat_fp MB/s"}

analyser:
    - name: analyse_train
      reduce: false
      use: perf_patterns
      analyse:
        step: train
        file:
            - stdout
            - job.out

result:
    - use: analyse_train
      table:
        name: result
        style: pretty
        sort: iter_pat
        column: 
          - {title: "JUBE id", _: jube_benchmark_id}
          - {title: "JUBE workpackage", _: jube_wp_id}
          - {title: "Exp", _: experiment}
          - {title: "JobID", _: jobid}
          - {title: "Host", _: hostname}
          - {title: "Hardware", _: hardware_name}
          - {title: "Steps per exectution", _: actual_steps_per_execution}
          - {title: "Replica", _: actual_replicas}
          - {title: "Processes", _: n_procs}
          - {title: "Dataset size [MB]", _: dataset_size_mb}
          - {title: "Samples per batch", _: batch_size}
          - {title: "Patch size", _: patch_size}
          - {title: "Batch size [MB]", _: batch_size_mb}
          - {title: "Batches per epoch", _: batches_per_epoch}
          - {title: "Epochs", _: nepochs}
          - {title: "Model", _: model}
          - {title: "Num weights", _: num_weights}
            # - {title: "num procs", _: n_procs}
            # - {title: "# cpu", _: threadspertask}
          - {title: "Training time", _: training_time}
            # - {title: "avg. epoch time [s]", _: epoch_time_avg}
          - {title: "First epoch [s]", _: epoch_time_first}
          - {title: "Performance [MB/s]", _: performance}
          - {title: "Non-first epoch [s]", _: epoch_time_nonfirst}
          - {title: "Performance [MB/s]", _: performance_nonfirst_epoch}
          - {title: "Best epoch [s]", _: epoch_time_min}
          - {title: "Performance [MB/s]", _: performance_min_epoch}
            # - {title: "max epoch time [s]", _: epoch_time_max}
          - {title: "Max cpu mem", _: cpu_mem}
          - {title: "Max gpu mem", _: gpu_mem}
          - {title: "Integrated Total Energy [J]", _: total_integrated_energy}
          - {title: "Counter Total Energy [J]", _: total_counter_energy}
          - {title: "Max Power [W]", _: max_power}

step:
  - name: setup_venv
    active: true
    use:
      - globalParameter
    do:
      _:
        $modules;
        $create_env;

  # Traning experiments
  - name: train
    active: true
    use:
      - appParameters
      - globalParameter
      - systemParameter
      - executeset
      - from: platform.xml
        _: jobfiles
      - from: platform.xml
        _: executesub
    do:
      done_file: $ready_file
      error_file: $error_file
      _: 
        $modules;
        $activate_env
        $submit $submit_script
