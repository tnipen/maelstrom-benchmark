name:    benchmark
outpath: results_ap1
comment: MAELSTROM GPU/CPU/IPU benchmark jube script
# Tags:
# - ipu (IPUS on dc-ipu). Must be scheduled from JURECA.
# - jwb (GPUs on JUWELS booster)
# - jwc (GPUs on JUWELS cluster)
# - jwr (A100 GPUs on JURECA cluster)
# - amd (CPUs on JUWELS booster)
# - intel (CPUs on JUWELS cluster)
# - h100 (GPUs on JURECA)
# - mi250x (GPUs on JURECA)

parameterset:
  - name: appParameters
    parameter:
      - name: program
        tag: jwb|jwc|jrc|amd|intel
        type: string
        _: python -u $jube_benchmark_home/../benchmark.py
      - name: program
        tag: "ipu"
        type: string
        _: apptainer run $jube_benchmark_home/../ipu.sif -- python -u $jube_benchmark_home/../benchmark.py
      - name: program
        tag: "h100"
        type: string
        _: --mpi=pspmix env PMIX_SECURITY_MODE=native apptainer run --nv $jube_benchmark_home/../h100.sif -- python -u $jube_benchmark_home/../benchmark.py
        #_: --mpi=pmi2 apptainer run --nv $jube_benchmark_home/../h100.sif -- python -u $jube_benchmark_home/../benchmark.py
      - name: program
        tag: "mi250x"
        type: string
        # This doesn't work. It makes each MPI task think there is only one task
        # _: --mpi=pspmix env PMIX_SECURITY_MODE=native apptainer run $jube_benchmark_home/../mi250x.sif -- python -u $jube_benchmark_home/../benchmark.py
        _: --mpi=pmi2 apptainer run $jube_benchmark_home/../mi250x.sif -- python -u $jube_benchmark_home/../benchmark.py
      - name: hardware_name
        type: string
        tag: jwb|jrc
        _: A100_GPU
      - name: hardware_name
        type: string
        tag: jwc
        _: V100_GPU
      - name: hardware_name
        type: string
        tag: ipu
        _: GC200_IPU
      - name: hardware_name
        type: string
        tag: intel
        _: Intel_Xeon_2.7GHz
      - name: hardware_name
        type: string
        tag: amd
        _: AMD_EPYC_2.8GHz
      - name: hardware_name
        type: string
        tag: h100
        _: H100_GPU
      - name: hardware_name
        type: string
        tag: mi250x
        _: MI250_GPU
      - name: hardware
        type: string
        tag: jwb|jwc|jrc|h100|mi250x
        _: gpu
      - name: hardware
        type: string
        tag: ipu
        _: ipu
      - name: hardware
        type: string
        tag: amd
        _: cpu
      - name: hardware
        type: string
        tag: intel
        _: cpu
      - name: experiment
        type: int
        _: 0,1,2
      - name: nepochs
        type: int
        _: 11
        # - name: batches_per_epoch
        # type: int
        # _: 80, 160, 320, 640
      - name: batch_size
        type: int
        tag: "jwc"
        _: 64,32,16,8,4,2,1
      - name: batch_size
        type: int
        tag: jwb|mi250x
        _: 256,128,64,32,16,8,4,2,1
        # _: 1
      - name: batch_size
        type: int
        tag: h100
        _: 512,256,128,64,32,16,8,4,2,1
        # _: 512
      - name: batch_size
        type: int
        tag: "ipu"
        _: 2
      - name: gradient_accumulation_steps
        type: int
        tag: "!ipu"
        _: 1
      - name: gradient_accumulation_steps
        type: int
        tag: ipu
        _: 1,2,4,8,16,32,64,128,256
        # _: 1,2,4,8,16
        # _: 1
      - name: replica
        tag: ipu
        type: int
        _: 4
      - name: replica
        tag: "!ipu"
        type: int
        _: 1
      - name: steps_per_execution
        tag: ipu
        type: int
        _: 4000000
      - name: steps_per_execution
        tag: "!ipu"
        type: int
        _: 4000
      - name: dataset_size
        tag: "!intel+!amd"
        type: int
        # _: 34359738368
        # This will make the batches break evenly into 8192
        _: 36507222016
        # _: 137438953472
      - name: dataset_size
        tag: "jrc"
        type: int
        _: 268435456
      - name: dataset_size
        # Use a smaller dataset for CPU benchmarks, otherwise it takes forever
        tag: intel|amd
        type: int
        _:   1073741824
      - name: patch_size
        type: int
        _: 256
      - name: app
        type: string
        _: ap1
      - name: program_args
        type: string
        _: "-a ${app} -b ${batch_size} -e ${nepochs} -d ${dataset_size} -p ${patch_size} -w ${hardware} -wn ${hardware_name} -s ${steps_per_execution} -g ${gradient_accumulation_steps} -r ${replica}"
  - name: globalParameter
    parameter:
      - name: create_env
        # ipu doesn't need any env activated, because it runs in the container
        tag: "jwb|jwc|amd|intel|jrc"
        separator: |
        _: 
          cd $jube_benchmark_home/../env_setup/;
          source ./create_env.sh venv_$systemname;
      - name: activate_env
        # ipu doesn't need any env activated, because it runs in the container
        tag: "jwb|jwc|amd|intel|jrc"
        separator: |
        _: 
          source $jube_benchmark_home/../virtual_envs/venv_$systemname/bin/activate
      - name: modules
        # ipu doesn't need any modules loaded, because it runs in the container
        tag: "jwb|jwc|amd|intel|jrc"
        separator: |
        _: 
          module load Stages/2022 &&
          module load GCCcore/.11.2.0 &&
          module load TensorFlow/2.6.0-CUDA-11.5 &&
          module load GCC/11.2.0 &&
          module load OpenMPI/4.1.2 &&
          module load mpi4py/3.1.3 &&
          module load Horovod/0.24.3  
      - name: systemname
        tag: jwc
        _: jwc
      - name: systemname
        tag: jrc
        _: jrc
      - name: systemname
        tag: jwb
        _: jwb
      - name: systemname
        tag: amd
        _: jwb
      - name: systemname
        tag: intel
        _: jwb
      - name: systemname
        tag: ipu|h100|mi250x
        _: jrc
  - name: executeset
    init_with: platform.xml
  - name: systemParameter
    init_with: platform.xml
    parameter:
      - name: preprocess
        mode: text
        tag: "jwb|jwc|amd|intel|jrc"
        _:
          $modules;
          $activate_env;

      - {name: n_cpu, _: 48, tag: jwb}
      - {name: n_cpu, _: 48, tag: jrc}
      - {name: n_cpu, _: 48, tag: amd}
      - {name: n_cpu, _: 48, tag: intel}
      - {name: n_cpu, _: 40, tag: jwc}
      - {name: n_cpu, _: 48, tag: ipu}
      - {name: n_cpu, _: 72, tag: h100}
        # Don't use 96 for mi250x, this causes communication errors
      - {name: n_cpu, _: 48, tag: mi250x}
      - name: SRUN_CPUS_PER_TASK
        export: true
        _: ${SLURM_CPUS_PER_TASK}
      - name: TF_POPLAR_FLAGS
        tag: ipu
        export: true
        _: --executable_cache_path=$jube_benchmark_home/ipu_cache/
      - name: nodes
        _: 1
      - name: n_procs
        tag: "!ipu+!mi250x"
        _: 1
      - name: n_procs
        tag: mi250x
        _: 8
      - name: n_procs
        tag: ipu
        _: 1
      - name: n_gpu
        _: $n_procs
      - name: taskspernode
        _: $n_procs
      - name: threadspertask
        mode: python
        type: int
        _:  $n_cpu // $n_procs
      - name: timelimit
        tag: "!ipu"
        _: "00:15:00"
      - name: timelimit
        tag: ipu
        _: "00:07:00"
      - name: account
        tag: jwb|jwc|amd|intel
        _: deepacf
      - name: account
        tag: jrc
        _: exalab
      - name: account
        tag: ipu|h100|mi250x|jrc
        _: exalab
      - name: queue
        tag: jwb|amd
        _: develbooster
      - name: queue
        tag: jwc
        _: develgpus
      - name: queue
        tag: intel
        _: batch
      - name: queue
        tag: ipu
        _: dc-ipu
      - name: queue
        tag: h100
        _: dc-h100
      - name: queue
        tag: mi250x
        _: dc-mi200
      - name: queue
        tag: jrc
        _: dc-gpu-devel
      - name: gres
        tag: jwb|jwc|jrc|h100
        _: gpu:$n_gpu
      - name: executable
        _: ${program}
      - name: args_exec
        mode: text
        _: > 
          ${program_args}

patternset:
   - name: perf_patterns
     pattern:
      - {name: jobid, type: int, _: "Submitted batch job $jube_pat_int" }
      - {name: hostname, type: string, _: "Hostname: $jube_pat_wrd" }
      - {name: training_time, type: float, _: "Total training time: ${jube_pat_fp} s"}
      - {name: num_weights, type: int, _: "Num trainable weights: ${jube_pat_int}"}
      - {name: dataset_size_mb, type: float, _: "Dataset size: ${jube_pat_fp} MB"}
      - {name: batch_size_mb, type: float, _: "Batch size: ${jube_pat_fp} MB"}
      - {name: effective_batch_size_mb, type: float, _: "Effective batch size: ${jube_pat_fp} MB"}
      - {name: batches_per_epoch, type: float, _: "Batches per epoch: ${jube_pat_int}"}
      - {name: actual_steps_per_execution, type: int, _: "Steps per execution: ${jube_pat_int}"}
      - {name: actual_replicas, type: int, _: "Num replicas: ${jube_pat_int}"}
      - {name: epoch_time_first, type: float, _: "First epoch time: $jube_pat_fp s"}
      - {name: epoch_time_nonfirst, type: float, _: "Non-first epoch time: $jube_pat_fp s"}
      - {name: epoch_time_min, type: float, _: "Min epoch time: $jube_pat_fp s"}
      - {name: epoch_time_avg, type: float, _: "Mean epoch time: $jube_pat_fp s"}
      - {name: epoch_time_max, type: float, _: "Max epoch time: $jube_pat_fp s"}
      - {name: cpu_mem, type: float, _: "CPU memory:.*peak: $jube_pat_fp GB"}
      - {name: gpu_mem, type: float, _: "GPU memory:.*peak: $jube_pat_fp GB"}
      - {name: gpu_mem, type: float, _: "GPU memory:.*peak: $jube_pat_fp GB"}
      - {name: total_integrated_energy, type: float, _: "Integrated Total Energy: ${jube_pat_fp} Wh"}
      - {name: total_counter_energy, type: float, _: "Counter Total Energy: ${jube_pat_fp} Wh"}
      - {name: max_power, type: float, _: "Max Power: ${jube_pat_fp} W"}
      - {name: max_agg_power, type: float, _: "Max Aggregate Power: ${jube_pat_fp} W"}
      - {name: mean_agg_power, type: float, _: "Mean Aggregate Power: ${jube_pat_fp} W"}
      - {name: performance, type: float, _: "Average performance:\\s+$jube_pat_fp MB/s"}
      - {name: performance_nonfirst_epoch, type: float, _: "Performance non-first epoch:\\s+$jube_pat_fp MB/s"}
      - {name: performance_min_epoch, type: float, _: "Performance min epoch:\\s+$jube_pat_fp MB/s"}

analyser:
    - name: analyse_train
      reduce: false
      use: perf_patterns
      analyse:
        step: train
        file:
            - stdout
            - job.out

result:
    - use: analyse_train
      table:
        name: result
        style: pretty
        sort: iter_pat
        column: 
          - {title: "JUBE id", _: jube_benchmark_id}
          - {title: "JUBE workpackage", _: jube_wp_id}
          - {title: "Exp", _: experiment}
          - {title: "JobID", _: jobid}
          - {title: "Host", _: hostname}
          - {title: "Hardware", _: hardware_name}
          - {title: "Steps per execution", _: actual_steps_per_execution}
          - {title: "Gradient accumulation steps", _: gradient_accumulation_steps}
          - {title: "Replica", _: actual_replicas}
          - {title: "Processes", _: n_procs}
          - {title: "Dataset size [MB]", _: dataset_size_mb}
          - {title: "Samples per batch", _: batch_size}
          - {title: "Patch size", _: patch_size}
          - {title: "Batch size [MB]", _: batch_size_mb}
          - {title: "Effective batch size [MB]", _: effective_batch_size_mb}
          - {title: "Batches per epoch", _: batches_per_epoch}
          - {title: "Epochs", _: nepochs}
          - {title: "Model", _: model}
          - {title: "Num weights", _: num_weights}
            # - {title: "num procs", _: n_procs}
            # - {title: "# cpu", _: threadspertask}
          - {title: "Training time", _: training_time}
            # - {title: "avg. epoch time [s]", _: epoch_time_avg}
          - {title: "First epoch [s]", _: epoch_time_first}
          - {title: "Performance [MB/s]", _: performance}
          - {title: "Non-first epoch [s]", _: epoch_time_nonfirst}
          - {title: "Performance [MB/s]", _: performance_nonfirst_epoch}
          - {title: "Best epoch [s]", _: epoch_time_min}
          - {title: "Performance [MB/s]", _: performance_min_epoch}
            # - {title: "max epoch time [s]", _: epoch_time_max}
          - {title: "Max cpu mem", _: cpu_mem}
          - {title: "Max gpu mem", _: gpu_mem}
          - {title: "Integrated Total Energy [Wh]", _: total_integrated_energy}
          - {title: "Counter Total Energy [Wh]", _: total_counter_energy}
          - {title: "Max Power [W]", _: max_power}
          - {title: "Max Aggregate Power [W]", _: max_agg_power}
          - {title: "Mean Aggregate Power [W]", _: mean_agg_power}

step:
  - name: setup_venv
    active: false
    use:
      - globalParameter
      - systemParameter
    do:
      _:
        $modules;
        $create_env;

  # Traning experiments
  - name: train
    active: true
    use:
      - appParameters
      - globalParameter
      - systemParameter
      - executeset
      - from: platform.xml
        _: jobfiles
      - from: platform.xml
        _: executesub
    do:
      done_file: $ready_file
      error_file: $error_file
      _: 
        $submit $submit_script
